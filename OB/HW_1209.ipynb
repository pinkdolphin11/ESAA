{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbxLL3lc0A1GZt6ZSyoas9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pinkdolphin11/ESAA/blob/main/HW_1209.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 4. 합성곱 신경망(CNN)"
      ],
      "metadata": {
        "id": "Ua59fYuGqtOE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.6 객체 탐지(Object Detection)"
      ],
      "metadata": {
        "id": "h0VbqxrDq1E6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6-1. 텐서플로 허브 활용"
      ],
      "metadata": {
        "id": "veLKQQQyrGkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf #tensorflow\n",
        "import tensorflow_hub as tfhub #tensorflow hub"
      ],
      "metadata": {
        "id": "pl72x4ujq8gA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6-1-1. 샘플 이미지 준비"
      ],
      "metadata": {
        "id": "j9XAVCd0rKot"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmELT1IJqsYB"
      },
      "outputs": [],
      "source": [
        "#샘플 이미지 다운로드\n",
        "img_path = 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Gangnam_Seoul_January_2009.jpg/1280px-Gangnam_Seoul_January_2009.jpg'\n",
        "img = tf.keras.utils.get_file(fname='gangnam', origin=img_path)\n",
        "img = tf.io.read_file(img) #파일 객체를 string으로 변환\n",
        "img = tf.image.decode_jpeg(img, channels=3) #문자(string)를 숫자(unit8) 텐서로 변환\n",
        "img = tf.image.convert_image_dtype(img, tf.float32) #0~1 범위로 정규화\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_input = tf.expand_dims(img, 0) #batch_size 추가\n",
        "img_input.shape"
      ],
      "metadata": {
        "id": "Tkl5gGxGrB3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6-1-2. 사전 학습 모델"
      ],
      "metadata": {
        "id": "sNnO4GGBrP6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TensorFlow Hub에서 모델 가져오기 - FasterRCNN + InceptionResNet V2\n",
        "model = tfhub.load('https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1')"
      ],
      "metadata": {
        "id": "P2CdyTMzrTNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 시그니처 (용도) 확인\n",
        "model.signatures.keys()"
      ],
      "metadata": {
        "id": "lSeknk_zrWAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#객체탐지 모델 생성\n",
        "obj_detector = model.signatures['default']\n",
        "obj_detector"
      ],
      "metadata": {
        "id": "V_om0OArrX49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6-1-3. 추론"
      ],
      "metadata": {
        "id": "Vjx6SdhJrYec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#모델을 이용하여 예측 (추론)\n",
        "result = obj_detector(img_input)\n",
        "result.keys() #딕셔너리 키 배열 확인"
      ],
      "metadata": {
        "id": "mxyHAXbprbar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#탐지한 객체의 개수\n",
        "len(result['detection_scores'])"
      ],
      "metadata": {
        "id": "61CVo6XGrdPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#객체 탐지 결과를 시각화\n",
        "boxes = result['detection_boxes'] #Bounding Box 좌표 예측 값\n",
        "labels = result['detection_class_entities'] #분류 예측 값\n",
        "scores = result['detection_scores'] #신뢰도 (confidence)\n",
        "\n",
        "#샘플 이미지 가로 세로 크기\n",
        "img_height, img_width = img.shape[0], img.shape[1]\n",
        "\n",
        "#탐지할 최대 객체의 수\n",
        "obj_to_detect = 10\n",
        "\n",
        "#시각화\n",
        "plt.figure(figsize=(15,10))\n",
        "for i in range(min(obj_to_detect, boxes.shape[0])):\n",
        "    if scores[i] >= 0.2:\n",
        "        (ymax, xmin, ymin, xmax) = (boxes[i][0] * img_height, boxes[i][1] * img_width, boxes[i][2] * img_height, boxes[i][3] * img_width)\n",
        "        \n",
        "        plt.imshow(img)\n",
        "        plt.plot([xmin, xmax, xmax, xmin, xmin], [ymin, ymin, ymax, ymax, ymin], color='yellow', linewidth=2)\n",
        "\n",
        "        class_name = labels[i].numpy().decode('utf-8')\n",
        "        infer_score = int(scores[i].numpy() * 100)\n",
        "        annotation = '{}: {}%'.format(class_name, infer_score)\n",
        "        plt.text(xmin+10, ymax+20, annotation, color='white', backgroundcolor='blue', fontsize=10)"
      ],
      "metadata": {
        "id": "L0TZjsE_re1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6-2. YOLO 객체 탐지"
      ],
      "metadata": {
        "id": "WAmA7EkRrgwV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6-2-1. Darknet YOLO 모델 추론하기"
      ],
      "metadata": {
        "id": "S3kfgWW2rk7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#깃허브 저장소 복제\n",
        "!git clone https://github.com/AlexeyAB/darknet"
      ],
      "metadata": {
        "id": "GA5SUcW7rjxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GPU 활성화\n",
        "%cd darknet\n",
        "!sed -i 's/GPU=0/GPU=1' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1' Makefile\n",
        "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1' Makefile\n",
        "\n",
        "#Darknet 생성\n",
        "!make"
      ],
      "metadata": {
        "id": "wKsmQQwOrp0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "img_path = 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Gangnam_Seoul_January_2009.jpg/1280px-Gangnam_Seoul_January_2009.jpg'\n",
        "img = tf.keras.utils.get_file(fname='gangnam.jpg', origin=img_path, cache_dir='/content')\n",
        "img = tf.io.read_file(img)\n",
        "img = tf.image.decode_jpeg(img, channels=3)\n",
        "img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "8G_I_aiIrtCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Darknet 실행\n",
        "!./darknet detector test cfg/coco.data cfg/yolov4.cfg yolov4.weights /content/datasets/gangnam.jpg"
      ],
      "metadata": {
        "id": "8_oBr9KorvCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "img = tf.io.read_file('/content/darknet/predictions.jpg')\n",
        "img = tf.image.decode_jpeg(img, channels=3)\n",
        "img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "Qj92gWonr0fH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6-2-2. 나만의 YOLO 모델 생성"
      ],
      "metadata": {
        "id": "ZMvcCCY7r4DP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#필요한 패키지 임포트\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "#파라미터 설정\n",
        "\n",
        "#이미지 크기\n",
        "width_size = 256\n",
        "height_size = 256\n",
        "channel_size = 3\n",
        "img_size = (width_size, height_size, channel_size)\n",
        "\n",
        "cell_num = 3 #이미지를 나눌 크기\n",
        "class_num = 3 #찾고자 하는 객체 개수\n",
        "\n",
        "#한 셀에 그릴 박스 수\n",
        "anchor_num = 1\n",
        "label_num = anchor_num * (5 + class_num)\n",
        "\n",
        "epoch_num = 500 #학습 수\n",
        "\n",
        "#로스 비중\n",
        "loss_p_rate = 1.0\n",
        "loss_cod_rate = 5.0\n",
        "loss_c_rate = 1.0\n",
        "loss_p_no_rate = 0.5"
      ],
      "metadata": {
        "id": "Bz_Cn2CYr7d4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "LG15tYS2r8BD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#랜덤하게 도형을 그리고, 실제 정답 값을 생성하는 함수 정의\n",
        "def make_img_label():\n",
        "    img = np.zeros((height_size + 400, width_size + 400, channel_size))\n",
        "    label = np.zeros((cell_num, cell_num, label_num))\n",
        "    num_shape = np.random.randint(1,4)\n",
        "    i = np.random.choice(range(cell_num), num_shape, replace=False)\n",
        "    j = np.random.choice(range(cell_num), num_shape, replace=False)\n",
        "    \n",
        "    img_0 = cv2.imread('/content/drive/MyDrive/ESAA/OB/Data/0.png')\n",
        "    img_1 = cv2.imread('/content/drive/MyDrive/ESAA/OB/Data/1.png')\n",
        "    img_2 = cv2.imread('/content/drive/MyDrive/ESAA/OB/Data/2.png')\n",
        "\n",
        "    for n_h in range(num_shape):\n",
        "        row = i[n_h]\n",
        "        col = j[n_h]\n",
        "        shape_type = np.random.randint(0, class_num)\n",
        "        x_rate = np.random.rand()\n",
        "        y_rate = np.random.rand()\n",
        "        w_rate = np.random.rand() * 0.3 + 0.1\n",
        "        h_rate = np.random.rand() * 0.3 + 0.1\n",
        "\n",
        "        label[row, col] = [1, x_rate, y_rate, w_rate, h_rate, 0, 0, 0]\n",
        "        label[row, col, 5 + shape_type] = 1\n",
        "        x = int(x_rate * width_size / cell_num + col * width_size / cell_num)\n",
        "        y = int(y_rate * height_size / cell_num + row * height_size / cell_num)\n",
        "        w = int(w_rate * width_size / 2) * 2\n",
        "        h = int(h_rate * height_size / 2) * 2\n",
        "        if(shape_type == 0):\n",
        "            input_img = cv2.resize(img_0, (w,h))\n",
        "        if(shape_type == 1):\n",
        "            input_img = cv2.resize(img_1, (w,h))\n",
        "        if(shape_type == 2):\n",
        "            input_img = cv2.resize(img_2, (w,h))\n",
        "        img[y-int(h/2)+200 : y+int(h/2)+200, x-int(w/2)+200 : x+int(w/2)+200] = input_img\n",
        "    img = img[200 : 200+height_size, 200 : 200+width_size]\n",
        "\n",
        "    return img, label"
      ],
      "metadata": {
        "id": "lSMdlCMdr-jT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = make_img_label()\n",
        "cv2_imshow(img)"
      ],
      "metadata": {
        "id": "gJnUo4IGr_6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#이미지와 정답 (혹은 예측 값)을 넣으면 박스를 그려주는 함수 정의\n",
        "#임계값 th 설정 (객체가 있다는 확률이 th 이상일 때만 박스 생성)\n",
        "def show_box(img, label, th=0.3):\n",
        "    b_img = np.zeros((height_size+400, width_size+400, 3))\n",
        "    b_img[200 : 200+height_size, 200 : 200+width_size] = img\n",
        "    for i in range(cell_num):\n",
        "        for j in range(cell_num):\n",
        "            if (label[i, j, 0] > th):\n",
        "                x_rate = label[i, j, 1]\n",
        "                y_rate = label[i, j, 2]\n",
        "                w_rate = label[i, j, 3]\n",
        "                h_rate = label[i, j, 4]\n",
        "                shape_type = np.argmax(label[i, j, 5:])\n",
        "                if (shape_type == 0):\n",
        "                    line_color = [0, 0, 255]\n",
        "                if (shape_type == 1):\n",
        "                    line_color = [255, 0, 0]\n",
        "                if (shape_type == 2):\n",
        "                    line_color = [0, 255, 0]\n",
        "                x = int(x_rate * width_size / 3 + j * width_size / 3)\n",
        "                y = int(y_rate * height_size / 3 + i * height_size / 3)\n",
        "                w = int(w_rate * width_size / 2) * 2 + 20\n",
        "                h = int(h_rate * height_size / 2) * 2 + 20\n",
        "                cv2.rectangle(b_img, (x-int(w/2)+200, y-int(h/2)+200), (x+int(w/2)+200, y+int(h/2)+200), line_color)\n",
        "            \n",
        "    b_img = b_img[200 : 200+height_size, 200 : 200+width_size]\n",
        "    return b_img"
      ],
      "metadata": {
        "id": "d2t9cyh5sB2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow(show_box(img, label))"
      ],
      "metadata": {
        "id": "s7-zd0zusDGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#VGG16모델을 베이스로 마지막 부분만 수정하는 모델 생성 (전이 학습)\n",
        "vgg_model = tf.keras.applications.VGG16(include_top=False, input_shape=img_size)\n",
        "vgg_model.trainable = False\n",
        "i = tf.keras.Input(shape=img_size)\n",
        "out = tf.keras.layers.Lambda((lambda x: x/255.))(i)\n",
        "out = vgg_model(out)\n",
        "out = tf.keras.layers.Conv2D(256, 3, padding='same')(out)\n",
        "out = tf.keras.layers.Conv2D(128, 3, padding='same')(out)\n",
        "out = tf.keras.layers.Conv2D(64, 3, padding='same')(out)\n",
        "out = tf.keras.layers.Flatten()(out)\n",
        "out = tf.keras.layers.Dense(1024, activation='relu')(out)\n",
        "out = tf.keras.layers.Dense(3 * 3 * 8, activation='relu')(out)\n",
        "out = tf.keras.layers.Reshape((3, 3, 8))(out)\n",
        "yolo_model = tf.keras.Model(inputs=[i], outputs=[out])\n",
        "opt = tf.keras.optimizers.Adam(0.00001)\n",
        "\n",
        "#모델 요약\n",
        "yolo_model.summary()"
      ],
      "metadata": {
        "id": "d2Ox4GaIsFDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#학습 과정을 동영상으로 기록\n",
        "fcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
        "out = cv2.VideoWriter('hjk_yolo.avi', fcc, 1, 0, (width_size, height_size))\n",
        "\n",
        "for e in range(epoch_num):\n",
        "    img, label = make_img_label()\n",
        "    img = np.reshape(img, (1, height_size, width_size, 3))\n",
        "    label = np.reshape(label, (1,3,3,8))\n",
        "\n",
        "    loss_p_list = []\n",
        "    loss_cod_list = []\n",
        "    loss_c_list = []\n",
        "    loss_p_no_list = []\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        pred = yolo_model(img)\n",
        "\n",
        "        #이미지를 구분한 셀을 탐험\n",
        "        for i in range(3):\n",
        "            for j in range(3):\n",
        "                #해당 셀에 객체가 있을 경우는 확률, 박스 크기, 클래스까지 모두 Loss로 계산\n",
        "                if(label[0,i,j,0] == 1):\n",
        "                    loss_p_list.append(tf.square(label[0,i,j,0] - pred[0,i,j,0]))\n",
        "                    loss_cod_list.append(tf.square(label[0,i,j,1] - pred[0,i,j,1]))\n",
        "                    loss_cod_list.append(tf.square(label[0,i,j,2] - pred[0,i,j,2]))\n",
        "                    loss_cod_list.append(tf.square(label[0,i,j,3] - pred[0,i,j,3]))\n",
        "                    loss_cod_list.append(tf.square(label[0,i,j,4] - pred[0,i,j,4]))\n",
        "                    loss_c_list.append(tf.square(label[0,i,j,5] - pred[0,i,j,5]))\n",
        "                    loss_c_list.append(tf.square(label[0,i,j,6] - pred[0,i,j,6]))\n",
        "                    loss_c_list.append(tf.square(label[0,i,j,7] - pred[0,i,j,7]))\n",
        "\n",
        "                #해당 셀에 객체가 없을 경우 객체가 없을 확률만 Loss로 계산\n",
        "                else:\n",
        "                    loss_p_no_list.append(tf.square(label[0,i,j,0] - pred[0,i,j,0]))\n",
        "\n",
        "        loss_p = tf.reduce_mean(loss_p_list)\n",
        "        loss_cod = tf.reduce_mean(loss_cod_list)\n",
        "        loss_c = tf.reduce_mean(loss_c_list)\n",
        "        loss_p_no = tf.reduce_mean(loss_p_no_list)\n",
        "\n",
        "        #각 Loss를 비중을 곱해 더해 최종 Loss를 계산\n",
        "        loss = loss_p_rate * loss_p + loss_cod_rate * loss_cod + loss_c_rate * loss_c + loss_p_no_rate * loss_p_no\n",
        "\n",
        "    #Loss에 대한 Grad를 구하고, 각 파라미터를 업데이트\n",
        "    vars = yolo_model.trainable_variables\n",
        "    grad = tape.gradient(loss, vars)\n",
        "    opt.apply_gradients(zip(grad, vars))\n",
        "\n",
        "    #100번마다 동영상에 이미지를 기록\n",
        "    if (e % 100 == 0):\n",
        "        img = np.reshape(img, (256,256,3))\n",
        "        label = pred.numpy()\n",
        "        label = np.reshape(label, (3,3,8))\n",
        "        sample_img = np.uint8(show_box(img, label))\n",
        "        out.write(sample_img)\n",
        "    print(e, '완료', loss.numpy())\n",
        "out.release()"
      ],
      "metadata": {
        "id": "Lzo2NjnysGvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.7 이미지 분할(Segmentation)"
      ],
      "metadata": {
        "id": "su24b1F7sIZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from tqdm.notebook import tqdm\n",
        "import tensorflow_datasets as tfds\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "yz-YLha6sMoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#이미지 크기\n",
        "img_w = 128\n",
        "img_h = 128\n",
        "img_c = 3\n",
        "img_shape = (img_w, img_h, img_c)\n",
        "\n",
        "#모델 학습\n",
        "epoch_num = 5\n",
        "learning_rate = 0.0001\n",
        "buffer_size = 1000\n",
        "batch_size = 16"
      ],
      "metadata": {
        "id": "Ushl16dfsOQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#텐서플로 데이터셋 로드\n",
        "ds_str = 'oxford_iiit_pet'\n",
        "ds, info = tfds.load(name=ds_str, with_info=True)"
      ],
      "metadata": {
        "id": "dAbJ0TjwsP0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#이미지 전처리 함수\n",
        "def preprocess_image(ds):\n",
        "    #원본 이미지\n",
        "    img = tf.image.resize(ds['image'], (img_w, img_h))\n",
        "    img = tf.cast(img, tf.float32) / 255.0\n",
        "\n",
        "    #분할 마스크 (0, 1, 2)\n",
        "    mask = tf.image.resize(ds['segmentation_mask'], (img_w, img_h))\n",
        "    mask = tf.cast(mask, tf.int32)\n",
        "    mask = mask - 1\n",
        "    return img, mask"
      ],
      "metadata": {
        "id": "XsJD3HZssRMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 전처리 파이프라인\n",
        "train_ds = ds['train'].map(preprocess_image).shuffle(buffer_size).batch(batch_size).prefetch(2)\n",
        "test_ds = ds['test'].map(preprocess_image).shuffle(buffer_size).batch(batch_size).prefetch(2)\n",
        "\n",
        "print(train_ds)"
      ],
      "metadata": {
        "id": "C4QjHMGpsSX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#샘플 배치 선택\n",
        "img, mask = next(iter(train_ds))\n",
        "len(img)"
      ],
      "metadata": {
        "id": "nUMEHXYYsTa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#샘플 이미지 출력\n",
        "img = np.array(img[0]) * 255.0\n",
        "img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "cv2_imshow(img)"
      ],
      "metadata": {
        "id": "lIf8j5H3sU9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#샘플 마스크 출력\n",
        "mask = (np.array(mask[0]/2)) * 255.0 #RGB 이미지로 표시\n",
        "cv2_imshow(mask)"
      ],
      "metadata": {
        "id": "Gl1vcSUjsWbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7-2. U-Net 모델(인코더-디코더)"
      ],
      "metadata": {
        "id": "mqRt6tYasXBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.VGG16(input_shape=img_shape, include_top=False) #include_top=False: 최종 레이어 제외"
      ],
      "metadata": {
        "id": "WHBTxI5QscpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 구조\n",
        "tf.keras.utils.plot_model(base_model, show_shapes=True)"
      ],
      "metadata": {
        "id": "wRaLqGwusfDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#VGG16 중간 레이어 출력 텐서를 지정\n",
        "f_model = tf.keras.Model(inputs=[base_model.input],\n",
        "                         outputs=[base_model.get_layer(name='block5_conv3').output,\n",
        "                                  base_model.get_layer(name='block4_conv3').output,\n",
        "                                  base_model.get_layer(name='block3_conv3').output,\n",
        "                                  base_model.get_layer(name='block2_conv2').output,\n",
        "                                  base_model.get_layer(name='block1_conv2').output])"
      ],
      "metadata": {
        "id": "Ri_QKuyfsg5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#파라미터 고정 (사전 학습된 파라미터를 인코더에 그대로 사용)\n",
        "f_model.trainable = False"
      ],
      "metadata": {
        "id": "iaRT_rjgshYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#U-Net 구조로 모델 정의\n",
        "\n",
        "i = tf.keras.Input(shape=img_shape)\n",
        "\n",
        "out_8_8_512, out_16_16_512, out_32_32_256, out_64_64_128, out_128_128_64 = f_model(i)\n",
        "\n",
        "out = tf.keras.layers.Conv2DTranspose(512, 3, strides=2, padding='same')(out_8_8_512)\n",
        "out = tf.keras.layers.Add()([out, out_16_16_512])\n",
        "\n",
        "out = tf.keras.layers.Conv2DTranspose(256, 3, strides=2, padding='same')(out)\n",
        "out = tf.keras.layers.Add()([out, out_32_32_256])\n",
        "\n",
        "out = tf.keras.layers.Conv2DTranspose(128, 3, strides=2, padding='same')(out)\n",
        "out = tf.keras.layers.Add()([out, out_64_64_128])\n",
        "\n",
        "out = tf.keras.layers.Conv2DTranspose(64, 3, strides=2, padding='same')(out)\n",
        "out = tf.keras.layers.Add()([out, out_128_128_64])\n",
        "\n",
        "out = tf.keras.layers.Conv2D(3, 3, activation='elu', padding='same')(out)\n",
        "out = tf.keras.layers.Dense(3, activation='softmax')(out)\n",
        "\n",
        "unet_model = tf.keras.Model(inputs=[i], outputs=[out])"
      ],
      "metadata": {
        "id": "In8HIaFasjjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 구조 시각화\n",
        "tf.keras.utils.plot_model(unet_model, show_shapes=True)"
      ],
      "metadata": {
        "id": "KMcLSp41smuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 요약\n",
        "unet_model.summary()"
      ],
      "metadata": {
        "id": "T4NlylSTsoBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 컴파일 및 훈련\n",
        "loss_f = tf.losses.SparseCategoricalCrossentropy() #예측 클래스 개수가 3개인 다중 분류 문제\n",
        "opt = tf.optimizers.Adam(learning_rate)\n",
        "\n",
        "unet_model.compile(optimizer=opt, loss=loss_f, metrics=['accuracy'])\n",
        "unet_model.fit(train_ds, batch_size=batch_size, epochs=epoch_num)"
      ],
      "metadata": {
        "id": "T-8MFG-vspjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1개 배치 (16개 이미지) 선택\n",
        "img, mask = next(iter(test_ds))\n",
        "\n",
        "#모델 예측\n",
        "pred = unet_model.predict(img)\n",
        "\n",
        "#첫 번째 이미지 분할 결과 출력\n",
        "pred_img = np.argmax(pred[0], -1)\n",
        "plt.imshow(pred_img)"
      ],
      "metadata": {
        "id": "dFytCcGMsqzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#첫 번재 이미지의 정답 마스크 출력\n",
        "plt.imshow(np.reshape(mask[0], (128,128)))"
      ],
      "metadata": {
        "id": "PQ-N1_CCssUE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
